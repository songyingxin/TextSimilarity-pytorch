
## Dataset

为了能够较公平的比较各个模型的优劣，本仓库尽可能的包含更多的数据集，并随时更新，如果有想添加的数据集，可以在 issue 中提出。 本仓库涉及到的数据集有：

- [AFQMC 蚂蚁金融语义相似度](https://www.cluebenchmarks.com/introduce.html) ：  
- [Quora Question Pairs](https://www.kaggle.com/c/quora-question-pairs/data): 
- [SST-B](https://gluebenchmark.com/tasks): 
- [MRPC](https://gluebenchmark.com/tasks): 


## 模型

本文相关的模型可以参见我的博客：



## Introduction
本仓库主要探讨 **BERT+ Attention 机制**在文本相似度，自然语言推理以及阅读理解等任务上的表现，并进行分析。 本仓库使用的数据集包括：

- Quora Question Pairs -- 英文
- 蚂蚁金服文本相似度数据集  -- 中文
- SQuAD -- 英文
- 百度阅读理解 -- 中文 ; <http://lic2019.ccf.org.cn/read>
- SNLI
- MultiNLI

<https://github.com/sebastianruder/NLP-progress/blob/master/english/semantic_textual_similarity.md>



<https://github.com/sebastianruder/NLP-progress/blob/master/english/question_answering.md>

<https://tech.meituan.com/2019/02/21/wsdm-cup-meituan-nlp-practice.html>

<https://tech.meituan.com/2019/01/25/ai-challenger-2018.html>

<https://hsiaoyetgun.github.io/2018/08/06/Natural-Language-Inference-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/>

<https://github.com/NTMC-Community/awesome-neural-models-for-semantic-match>

